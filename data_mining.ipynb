{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy seaborn matplotlib mlxtend pyfim kagglehub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mineria de patrones - Online Retail\n",
        "\n",
        "Frequent itemsets, reglas de asociacion y patrones emergentes sobre el dataset limpio. Incluye opcion de preprocesamiento en GPU (cudf) y conversion a pandas para FP-Growth.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos\n",
        "- Preparar transacciones con un unico espacio de items (encoder unico)\n",
        "- Obtener itemsets frecuentes y reglas (soporte, confianza, lift)\n",
        "- Comparar particiones temporales (H1 vs H2 2011) con growth rate\n",
        "- Exportar resultados y graficas para observabilidad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules, fpmax\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "# GPU opcional\n",
        "try:\n",
        "    import cudf\n",
        "    USE_GPU_DEFAULT = True\n",
        "except ImportError:\n",
        "    cudf = None\n",
        "    USE_GPU_DEFAULT = False\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "pd.options.display.float_format = \"{:,.4f}\".format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuracion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USE_GPU=False (cudf no disponible)\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "PROCESSED_PATH = DATA_DIR / \"processed\" / \"cleaned_online_retail.csv\"\n",
        "RESULTS_DIR = DATA_DIR / \"processed\"\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Parametros\n",
        "MIN_SUPPORT = 0.01\n",
        "MAX_LEN = None  # ejemplo: 3 para limitar\n",
        "MIN_CONFIDENCE = 0.3\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "USE_GPU = USE_GPU_DEFAULT  # cambia a False si quieres forzar CPU\n",
        "print(f\"USE_GPU={USE_GPU} (cudf {'disponible' if cudf else 'no disponible'})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga del dataset procesado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 494,588 | Items unicos: 2190 | Facturas: 19748\n",
            "   InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER    6.0000   \n",
            "1     536365     71053                  WHITE METAL LANTERN    6.0000   \n",
            "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER    8.0000   \n",
            "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE    6.0000   \n",
            "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.    6.0000   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0 2010-12-01 08:26:00     2.5500 17,850.0000  United Kingdom  \n",
            "1 2010-12-01 08:26:00     3.3900 17,850.0000  United Kingdom  \n",
            "2 2010-12-01 08:26:00     2.7500 17,850.0000  United Kingdom  \n",
            "3 2010-12-01 08:26:00     3.3900 17,850.0000  United Kingdom  \n",
            "4 2010-12-01 08:26:00     3.3900 17,850.0000  United Kingdom  \n",
            "DataFrame en CPU\n"
          ]
        }
      ],
      "source": [
        "if not PROCESSED_PATH.exists():\n",
        "    raise FileNotFoundError(\"Ejecuta primero eda.ipynb para generar cleaned_online_retail.csv\")\n",
        "\n",
        "df_pd = pd.read_csv(PROCESSED_PATH)\n",
        "df_pd['InvoiceDate'] = pd.to_datetime(df_pd['InvoiceDate'])\n",
        "\n",
        "df = cudf.from_pandas(df_pd) if (USE_GPU and cudf is not None) else df_pd\n",
        "print(f\"Filas: {len(df_pd):,} | Items unicos: {df_pd['Description'].nunique()} | Facturas: {df_pd['InvoiceNo'].nunique()}\")\n",
        "print(df_pd.head())\n",
        "print(f\"DataFrame en {'GPU' if USE_GPU and cudf else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Particiones temporales\n",
        "Se separa 2011 en dos mitades para observar cambios estacionales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H1: 188,150 filas, 8024 facturas\n",
            "H2: 306,438 filas, 11724 facturas\n"
          ]
        }
      ],
      "source": [
        "cutoff = pd.Timestamp('2011-06-01')\n",
        "part1 = df[df['InvoiceDate'] < cutoff]\n",
        "part2 = df[df['InvoiceDate'] >= cutoff]\n",
        "\n",
        "print(f\"H1: {len(part1):,} filas, {part1['InvoiceNo'].nunique()} facturas\")\n",
        "print(f\"H2: {len(part2):,} filas, {part2['InvoiceNo'].nunique()} facturas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparacion de transacciones (encoder unico)\n",
        "Se ajusta `TransactionEncoder` con todas las transacciones para garantizar el mismo espacio de items en cada particion. Se usa pandas para el encoding, pero los filtros previos pueden correr en GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Items en espacio comun: 2190\n",
            "Transacciones totales: 19,748 | H1: 8,024 | H2: 11,724\n",
            "Densidad promedio one-hot (ALL): 0.0113\n"
          ]
        }
      ],
      "source": [
        "def to_pandas(df_like):\n",
        "    return df_like.to_pandas() if hasattr(df_like, 'to_pandas') else df_like\n",
        "\n",
        "\n",
        "def build_transactions(df_part_pd):\n",
        "    return df_part_pd.groupby('InvoiceNo')['Description'].apply(list).tolist()\n",
        "\n",
        "# Convertimos a pandas para TransactionEncoder\n",
        "part1_pd = to_pandas(part1)\n",
        "part2_pd = to_pandas(part2)\n",
        "df_all_pd = to_pandas(df)\n",
        "\n",
        "transactions_all = build_transactions(df_all_pd)\n",
        "transactions1 = build_transactions(part1_pd)\n",
        "transactions2 = build_transactions(part2_pd)\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary_all = te.fit(transactions_all).transform(transactions_all)\n",
        "onehot_all = pd.DataFrame(te_ary_all, columns=te.columns_)\n",
        "\n",
        "# Reusar las mismas columnas para las particiones\n",
        "te_ary_1 = te.transform(transactions1)\n",
        "onehot_1 = pd.DataFrame(te_ary_1, columns=te.columns_)\n",
        "\n",
        "te_ary_2 = te.transform(transactions2)\n",
        "onehot_2 = pd.DataFrame(te_ary_2, columns=te.columns_)\n",
        "\n",
        "print(f\"Items en espacio comun: {onehot_all.shape[1]}\")\n",
        "print(f\"Transacciones totales: {len(transactions_all):,} | H1: {len(transactions1):,} | H2: {len(transactions2):,}\")\n",
        "print(f\"Densidad promedio one-hot (ALL): {onehot_all.values.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcion auxiliar para itemsets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m freq_all \u001b[38;5;241m=\u001b[39m run_fpgrowth(onehot_all)\n\u001b[1;32m     12\u001b[0m freq_p1 \u001b[38;5;241m=\u001b[39m run_fpgrowth(onehot_1)\n\u001b[0;32m---> 13\u001b[0m freq_p2 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fpgrowth\u001b[49m\u001b[43m(\u001b[49m\u001b[43monehot_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m top_summary(freq_all, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset completo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m top_summary(freq_p1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mrun_fpgrowth\u001b[0;34m(df_oh, min_support, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_fpgrowth\u001b[39m(df_oh, min_support\u001b[38;5;241m=\u001b[39mMIN_SUPPORT, max_len\u001b[38;5;241m=\u001b[39mMAX_LEN):\n\u001b[0;32m----> 2\u001b[0m     freq \u001b[38;5;241m=\u001b[39m \u001b[43mfpgrowth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_oh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_support\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_colnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     freq \u001b[38;5;241m=\u001b[39m freq\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m freq\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpgrowth.py:95\u001b[0m, in \u001b[0;36mfpgrowth\u001b[0;34m(df, min_support, null_values, use_colnames, max_len, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m minsup \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(min_support \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex))  \u001b[38;5;66;03m# min support as count\u001b[39;00m\n\u001b[1;32m     93\u001b[0m generator \u001b[38;5;241m=\u001b[39m fpg_step(tree, minsup, colname_map, max_len, verbose)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_itemsets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolname_map\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:74\u001b[0m, in \u001b[0;36mgenerate_itemsets\u001b[0;34m(generator, df, disabled, min_support, num_itemsets, colname_map)\u001b[0m\n\u001b[1;32m     72\u001b[0m itemsets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m supports \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 74\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitemsets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfrozenset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# select data of iset from disabled dataset\u001b[39;49;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpgrowth.py:139\u001b[0m, in \u001b[0;36mfpg_step\u001b[0;34m(tree, minsup, colnames, max_len, verbose)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mis_path() \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m max_len \u001b[38;5;129;01mor\u001b[39;00m max_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(tree\u001b[38;5;241m.\u001b[39mcond_items)):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m--> 139\u001b[0m         cond_tree \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditional_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminsup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sup, iset \u001b[38;5;129;01min\u001b[39;00m fpg_step(cond_tree, minsup, colnames, max_len, verbose):\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m sup, iset\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:241\u001b[0m, in \u001b[0;36mFPTree.conditional_tree\u001b[0;34m(self, cond_item, minsup)\u001b[0m\n\u001b[1;32m    239\u001b[0m     branches\u001b[38;5;241m.\u001b[39mappend(branch)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m branch:\n\u001b[0;32m--> 241\u001b[0m         count[item] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mcount\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Define new ordering or deep trees may have combinatorially explosion\u001b[39;00m\n\u001b[1;32m    244\u001b[0m items \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m count \u001b[38;5;28;01mif\u001b[39;00m count[item] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m minsup]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def run_fpgrowth(df_oh, min_support=MIN_SUPPORT, max_len=MAX_LEN):\n",
        "    freq = fpgrowth(df_oh, min_support=min_support, use_colnames=True, max_len=max_len)\n",
        "    freq = freq.sort_values(by='support', ascending=False).reset_index(drop=True)\n",
        "    return freq\n",
        "\n",
        "\n",
        "def top_summary(freq, name, n=5):\n",
        "    print(f\"Top {n} itemsets frecuentes - {name}\")\n",
        "    print(freq.head(n))\n",
        "\n",
        "freq_all = run_fpgrowth(onehot_all)\n",
        "freq_p1 = run_fpgrowth(onehot_1)\n",
        "freq_p2 = run_fpgrowth(onehot_2)\n",
        "\n",
        "top_summary(freq_all, \"Dataset completo\")\n",
        "top_summary(freq_p1, \"H1\")\n",
        "top_summary(freq_p2, \"H2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reglas de asociacion (dataset completo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rules = association_rules(freq_all, metric='confidence', min_threshold=MIN_CONFIDENCE)\n",
        "rules = rules.sort_values(by='lift', ascending=False)\n",
        "print(f\"Reglas generadas: {len(rules)}\")\n",
        "print(rules[['antecedents','consequents','support','confidence','lift']].head())\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(rules['support'], rules['confidence'], c=rules['lift'], cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(label='Lift')\n",
        "plt.xlabel('Support')\n",
        "plt.ylabel('Confidence')\n",
        "plt.title('Mapa Support vs Confidence (color = Lift)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Patrones emergentes (growth rate H2 vs H1)\n",
        "Se calcula growth rate comparando soportes de los mismos itemsets entre H1 y H2. Los inf son Jumping Emerging Patterns (JEP).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged = pd.merge(freq_p1, freq_p2, on='itemsets', how='outer', suffixes=('_1', '_2')).fillna(0)\n",
        "merged['growth_rate'] = np.where(\n",
        "    merged['support_1'] == 0,\n",
        "    np.inf,\n",
        "    merged['support_2'] / merged['support_1']\n",
        ")\n",
        "\n",
        "merged = merged.sort_values(by='growth_rate', ascending=False)\n",
        "\n",
        "# Segmentos\n",
        "jep = merged[merged['growth_rate'] == np.inf].sort_values(by='support_2', ascending=False)\n",
        "inc = merged[(merged['growth_rate'] > 1) & (merged['growth_rate'] != np.inf)].sort_values(by='growth_rate', ascending=False)\n",
        "stable = merged[(merged['growth_rate'] >= 0.8) & (merged['growth_rate'] <= 1.2)].sort_values(by='support_2', ascending=False)\n",
        "dec = merged[(merged['growth_rate'] < 0.8) & (merged['support_2'] > 0)].sort_values(by='growth_rate')\n",
        "\n",
        "print(f\"Itemsets comparados: {len(merged)}\")\n",
        "print(f\"JEPs: {len(jep)} | Incrementan: {len(inc)} | Estables: {len(stable)} | Decrecen: {len(dec)}\")\n",
        "print(\"Top 5 JEP (por soporte H2):\")\n",
        "print(jep.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizaciones de patrones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iset_to_str(s):\n",
        "    try:\n",
        "        return ', '.join(sorted(s))\n",
        "    except Exception:\n",
        "        return str(s)\n",
        "\n",
        "# Top growth (sin inf)\n",
        "top_inc = inc.head(10).copy()\n",
        "top_inc['item'] = top_inc['itemsets'].apply(iset_to_str)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(top_inc['item'], top_inc['growth_rate'], color='teal')\n",
        "plt.xticks(rotation=60, ha='right')\n",
        "plt.ylabel('Growth rate (H2/H1)')\n",
        "plt.title('Top 10 Emerging Patterns (sin JEP)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# JEPs mas soportados\n",
        "top_jep = jep.head(10).copy()\n",
        "top_jep['item'] = top_jep['itemsets'].apply(iset_to_str)\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.barplot(x=top_jep['support_2'], y=top_jep['item'], palette='flare')\n",
        "plt.xlabel('Support H2')\n",
        "plt.title('Top 10 Jumping Emerging Patterns')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top soportes por particion\n",
        "for name, freq_df in [(\"H1\", freq_p1), (\"H2\", freq_p2)]:\n",
        "    top_support = freq_df.head(10).copy()\n",
        "    top_support['item'] = top_support['itemsets'].apply(iset_to_str)\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.barplot(x=top_support['support'], y=top_support['item'], palette='crest')\n",
        "    plt.title(f'Top 10 itemsets por soporte - {name}')\n",
        "    plt.xlabel('Support')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exportar resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freq_all.to_csv(RESULTS_DIR / 'frequent_itemsets_all.csv', index=False)\n",
        "freq_p1.to_csv(RESULTS_DIR / 'frequent_itemsets_h1.csv', index=False)\n",
        "freq_p2.to_csv(RESULTS_DIR / 'frequent_itemsets_h2.csv', index=False)\n",
        "rules.to_csv(RESULTS_DIR / 'association_rules_all.csv', index=False)\n",
        "merged.to_csv(RESULTS_DIR / 'growth_rates_h1_vs_h2.csv', index=False)\n",
        "print(\"Archivos guardados en data/processed/\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
