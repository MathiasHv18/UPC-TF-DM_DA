{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mineria de patrones - Online Retail\n",
        "\n",
        "Frequent itemsets, reglas de asociacion y patrones emergentes sobre el dataset limpio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos\n",
        "- Preparar transacciones con un unico espacio de items (encoder unico)\n",
        "- Obtener itemsets frecuentes y reglas (soporte, confianza, lift)\n",
        "- Comparar particiones temporales (H1 vs H2 2011) con growth rate\n",
        "- Exportar resultados a disco y generar visualizaciones basicas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules, fpmax\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "pd.options.display.float_format = \"{:,.4f}\".format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuracion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "PROCESSED_PATH = DATA_DIR / \"processed\" / \"cleaned_online_retail.csv\"\n",
        "RESULTS_DIR = DATA_DIR / \"processed\"\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Parametros\n",
        "MIN_SUPPORT = 0.01\n",
        "MAX_LEN = None  # ejemplo: 3 para limitar\n",
        "MIN_CONFIDENCE = 0.3\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga del dataset procesado\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if not PROCESSED_PATH.exists():\n",
        "    raise FileNotFoundError(\"Ejecuta primero eda.ipynb para generar cleaned_online_retail.csv\")\n",
        "\n",
        "df = pd.read_csv(PROCESSED_PATH)\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "print(f\"Filas: {len(df):,} | Items unicos: {df['Description'].nunique()} | Facturas: {df['InvoiceNo'].nunique()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Particiones temporales\n",
        "Se separa 2011 en dos mitades para observar cambios estacionales.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cutoff = pd.Timestamp('2011-06-01')\n",
        "part1 = df[df['InvoiceDate'] < cutoff]\n",
        "part2 = df[df['InvoiceDate'] >= cutoff]\n",
        "\n",
        "print(f\"H1: {len(part1):,} filas, {part1['InvoiceNo'].nunique()} facturas\")\n",
        "print(f\"H2: {len(part2):,} filas, {part2['InvoiceNo'].nunique()} facturas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparacion de transacciones (encoder unico)\n",
        "Se ajusta `TransactionEncoder` con todas las transacciones para garantizar el mismo espacio de items en cada particion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_transactions(df_part):\n",
        "    return df_part.groupby('InvoiceNo')['Description'].apply(list).tolist()\n",
        "\n",
        "transactions_all = build_transactions(df)\n",
        "transactions1 = build_transactions(part1)\n",
        "transactions2 = build_transactions(part2)\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary_all = te.fit(transactions_all).transform(transactions_all)\n",
        "onehot_all = pd.DataFrame(te_ary_all, columns=te.columns_)\n",
        "\n",
        "# Reusar las mismas columnas para las particiones\n",
        "te_ary_1 = te.transform(transactions1)\n",
        "onehot_1 = pd.DataFrame(te_ary_1, columns=te.columns_)\n",
        "\n",
        "te_ary_2 = te.transform(transactions2)\n",
        "onehot_2 = pd.DataFrame(te_ary_2, columns=te.columns_)\n",
        "\n",
        "print(f\"Items en espacio comun: {onehot_all.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcion auxiliar para itemsets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_fpgrowth(df_oh, min_support=MIN_SUPPORT, max_len=MAX_LEN):\n",
        "    freq = fpgrowth(df_oh, min_support=min_support, use_colnames=True, max_len=max_len)\n",
        "    freq = freq.sort_values(by='support', ascending=False).reset_index(drop=True)\n",
        "    return freq\n",
        "\n",
        "\n",
        "def top_summary(freq, name, n=5):\n",
        "    print(f\"Top {n} itemsets frecuentes - {name}\")\n",
        "    print(freq.head(n))\n",
        "\n",
        "freq_all = run_fpgrowth(onehot_all)\n",
        "freq_p1 = run_fpgrowth(onehot_1)\n",
        "freq_p2 = run_fpgrowth(onehot_2)\n",
        "\n",
        "top_summary(freq_all, \"Dataset completo\")\n",
        "top_summary(freq_p1, \"H1\")\n",
        "top_summary(freq_p2, \"H2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reglas de asociacion (dataset completo)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "rules = association_rules(freq_all, metric='confidence', min_threshold=MIN_CONFIDENCE)\n",
        "rules = rules.sort_values(by='lift', ascending=False)\n",
        "print(f\"Reglas generadas: {len(rules)}\")\n",
        "rules[['antecedents','consequents','support','confidence','lift']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Patrones emergentes (growth rate H2 vs H1)\n",
        "Se calcula growth rate comparando soportes de los mismos itemsets entre H1 y H2. Los inf son Jumping Emerging Patterns (JEP).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "merged = pd.merge(freq_p1, freq_p2, on='itemsets', how='outer', suffixes=('_1', '_2')).fillna(0)\n",
        "merged['growth_rate'] = np.where(\n",
        "    merged['support_1'] == 0,\n",
        "    np.inf,\n",
        "    merged['support_2'] / merged['support_1']\n",
        ")\n",
        "\n",
        "merged = merged.sort_values(by='growth_rate', ascending=False)\n",
        "\n",
        "# Segmentos\n",
        "jep = merged[merged['growth_rate'] == np.inf].sort_values(by='support_2', ascending=False)\n",
        "inc = merged[(merged['growth_rate'] > 1) & (merged['growth_rate'] != np.inf)].sort_values(by='growth_rate', ascending=False)\n",
        "stable = merged[(merged['growth_rate'] >= 0.8) & (merged['growth_rate'] <= 1.2)].sort_values(by='support_2', ascending=False)\n",
        "dec = merged[(merged['growth_rate'] < 0.8) & (merged['support_2'] > 0)].sort_values(by='growth_rate')\n",
        "\n",
        "print(f\"Itemsets comparados: {len(merged)}\")\n",
        "print(f\"JEPs: {len(jep)} | Incrementan: {len(inc)} | Estables: {len(stable)} | Decrecen: {len(dec)}\")\n",
        "\n",
        "merged.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizaciones de patrones\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def iset_to_str(s):\n",
        "    try:\n",
        "        return ', '.join(sorted(s))\n",
        "    except Exception:\n",
        "        return str(s)\n",
        "\n",
        "# Top growth (sin inf)\n",
        "top_inc = inc.head(10).copy()\n",
        "top_inc['item'] = top_inc['itemsets'].apply(iset_to_str)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(top_inc['item'], top_inc['growth_rate'], color='teal')\n",
        "plt.xticks(rotation=60, ha='right')\n",
        "plt.ylabel('Growth rate (H2/H1)')\n",
        "plt.title('Top 10 Emerging Patterns (sin JEP)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top soportes por particion\n",
        "for name, freq_df in [(\"H1\", freq_p1), (\"H2\", freq_p2)]:\n",
        "    top_support = freq_df.head(10).copy()\n",
        "    top_support['item'] = top_support['itemsets'].apply(iset_to_str)\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.barplot(x=top_support['support'], y=top_support['item'], palette='crest')\n",
        "    plt.title(f'Top 10 itemsets por soporte - {name}')\n",
        "    plt.xlabel('Support')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exportar resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "freq_all.to_csv(RESULTS_DIR / 'frequent_itemsets_all.csv', index=False)\n",
        "freq_p1.to_csv(RESULTS_DIR / 'frequent_itemsets_h1.csv', index=False)\n",
        "freq_p2.to_csv(RESULTS_DIR / 'frequent_itemsets_h2.csv', index=False)\n",
        "rules.to_csv(RESULTS_DIR / 'association_rules_all.csv', index=False)\n",
        "merged.to_csv(RESULTS_DIR / 'growth_rates_h1_vs_h2.csv', index=False)\n",
        "print(\"Archivos guardados en data/processed/\")\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
